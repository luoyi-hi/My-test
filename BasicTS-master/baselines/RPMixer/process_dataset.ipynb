{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/path/to/LTSF-Benchmark' \n",
    "# This folder needs to contain folders \"electricity\", \"traffic\", \n",
    "# \"weather\", and \"ETT-small\".\n",
    "output_dir = '/path/to/the/output/folder'\n",
    "\n",
    "dataset_paths = [\n",
    "    os.path.join(dataset_dir, 'electricity', 'electricity.csv'),\n",
    "    os.path.join(dataset_dir, 'traffic', 'traffic.csv'),\n",
    "    os.path.join(dataset_dir, 'weather', 'weather.csv'),\n",
    "    os.path.join(dataset_dir, 'ETT-small', 'TTh1.csv'),\n",
    "    os.path.join(dataset_dir, 'ETT-small', 'TTh2.csv'),\n",
    "    os.path.join(dataset_dir, 'ETT-small', 'TTm1.csv'),\n",
    "    os.path.join(dataset_dir, 'ETT-small', 'TTm2.csv'),\n",
    "]\n",
    "\n",
    "output_paths = [\n",
    "    os.path.join(output_dir, 'Electricity.npz'),\n",
    "    os.path.join(output_dir, 'Traffic.npz'),\n",
    "    os.path.join(output_dir, 'Weather.npz'),\n",
    "    os.path.join(output_dir, 'ETTh1.npz'),\n",
    "    os.path.join(output_dir, 'ETTh2.npz'),\n",
    "    os.path.join(output_dir, 'ETTm1.npz'),\n",
    "    os.path.join(output_dir, 'ETTm2.npz'),\n",
    "]\n",
    "\n",
    "for dataset_path, output_path in zip(dataset_paths, output_paths):\n",
    "    if os.path.isfile(output_path):\n",
    "        npz = np.load(output_path)\n",
    "        data = npz['data']\n",
    "        print(output_path, data.shape)\n",
    "        continue\n",
    "    data = []\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            line = line.split(',')\n",
    "            if line[0] == 'date':\n",
    "                continue\n",
    "            line = line[1:]\n",
    "            line = np.array(line, dtype=float)\n",
    "            data.append(line)\n",
    "    data = np.array(data)\n",
    "    print(output_path, data.shape)\n",
    "    np.savez_compressed(output_path, data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_dir, output_dir, dataset_names, suffix, is_agg):\n",
    "    subset_names = ['ca', 'gba', 'gla', 'sd', ]\n",
    "    subset_districts = [None, [4, ], [7, 8, 12, ], [11, ], ]\n",
    "    direction_map = {'E': 0, 'W': 1, 'S': 2, 'N': 3, }\n",
    "\n",
    "    meta_path = os.path.join(\n",
    "        dataset_dir, 'ca_meta.csv')\n",
    "\n",
    "    for subset_name, subset_district in zip(subset_names, subset_districts):\n",
    "        output_path = os.path.join(\n",
    "            output_dir, f'{subset_name}_his_{suffix}.npz')\n",
    "        if os.path.isfile(output_path):\n",
    "            npz = np.load(output_path)\n",
    "            data = npz['data']\n",
    "            print(output_path, data.shape)\n",
    "            continue\n",
    "\n",
    "        subset_id = []\n",
    "        lat = []\n",
    "        lng = []\n",
    "        direction = []\n",
    "        with open(meta_path, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip('\\n')\n",
    "                line = line.split(',')\n",
    "                if line[0] == 'ID':\n",
    "                    continue\n",
    "\n",
    "                district = int(line[3])\n",
    "                if subset_district is None or district in subset_district:\n",
    "                    subset_id.append(line[0])\n",
    "                    lat.append(float(line[1]))\n",
    "                    lng.append(float(line[2]))\n",
    "                    direction.append(direction_map[line[8]])\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        tod = []\n",
    "        dow = []\n",
    "\n",
    "        for dataset_name in dataset_names:\n",
    "            dataset_path = os.path.join(dataset_dir, dataset_name)\n",
    "            df_tmp = pd.read_hdf(dataset_path)\n",
    "            if subset_district is not None:\n",
    "                df_tmp = df_tmp[subset_id]\n",
    "            if is_agg:\n",
    "                df_tmp = df_tmp.resample('15T').mean().round(0)\n",
    "            df_tmp = df_tmp.fillna(0)\n",
    "            tod_ = (df_tmp.index.values - df_tmp.index.values.astype('datetime64[D]')) / np.timedelta64(1, 'D')\n",
    "            dow_ = df_tmp.index.dayofweek / 7\n",
    "\n",
    "            tod.append(tod_)\n",
    "            dow.append(dow_)\n",
    "\n",
    "            df = pd.concat([df, df_tmp, ], ignore_index=True)\n",
    "\n",
    "        data = df.values\n",
    "\n",
    "        tod = np.concatenate(tod, axis=0)\n",
    "        dow = np.concatenate(dow, axis=0)\n",
    "\n",
    "        lat = np.array(lat)\n",
    "        lng = np.array(lng)\n",
    "        direction = np.array(direction)\n",
    "        print(output_path, data.shape)\n",
    "        np.savez_compressed(\n",
    "            output_path, data=data, tod=tod, dow=dow, lat=lat, lng=lng, \n",
    "            direction=direction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_60048\\1278057783.py:46: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_tmp = df_tmp.resample('15T').mean().round(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data\\ca_his_2019_agg.npz (35040, 8600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_60048\\1278057783.py:46: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_tmp = df_tmp.resample('15T').mean().round(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data\\gba_his_2019_agg.npz (35040, 2352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_60048\\1278057783.py:46: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_tmp = df_tmp.resample('15T').mean().round(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data\\gla_his_2019_agg.npz (35040, 3834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_60048\\1278057783.py:46: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  df_tmp = df_tmp.resample('15T').mean().round(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_data\\sd_his_2019_agg.npz (35040, 716)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = 'data' \n",
    "# This folder needs to contain \"ca_his_raw_2019.h5\" and \"ca_meta.csv\".\n",
    "output_dir = 'process_data'\n",
    "\n",
    "dataset_names = [\n",
    "    'ca_his_raw_2019.h5',\n",
    "]\n",
    "\n",
    "suffix = '2019_agg'\n",
    "process_dataset(dataset_dir, output_dir, dataset_names, suffix, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BasicTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
